"""Metrics visualization module for ccwatch.

This module handles the display of basic metrics and statistics in the Streamlit UI.
"""

from typing import Optional

import pandas as pd
import streamlit as st

from calculations.cost import calculate_cache_savings
from utils.logging_config import get_logger, log_with_context

# Initialize logger
logger = get_logger()


def show_metrics(df: pd.DataFrame) -> None:
    """Display basic metrics in a grid layout.

    Args:
        df: Assistant messages dataframe with token and session information
    """
    if df.empty:
        st.warning("No data available to display metrics")
        return

    # Log metrics display
    log_with_context(logger, "DEBUG", "Displaying metrics", total_rows=len(df), sessions=df["session_id"].nunique())

    # First row: basic metrics
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric(
            "AI Responses",
            len(df),
            help="Total number of AI assistant responses recorded across all projects and sessions.",
        )
    with col2:
        st.metric(
            "Sessions",
            df["session_id"].nunique(),
            help="Number of unique ClaudeCode sessions. "
            "Each session represents a distinct conversation or work period.",
        )
    with col3:
        st.metric("Projects", df["project_path"].nunique(), help="Number of unique projects where ClaudeCode was used.")
    with col4:
        st.metric(
            "Models", df["model"].nunique(), help="Number of different Claude models used (e.g., Sonnet, Opus, Haiku)."
        )

    # Second row: token metrics
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        total_input = df["effective_input_tokens"].sum()
        st.metric(
            "Total Input Tokens",
            f"{total_input:,.0f}",
            help="Total effective input tokens consumed. Cache read tokens are counted as 10% of regular tokens.",
        )
    with col2:
        total_output = df["output_tokens"].sum()
        st.metric(
            "Total Output Tokens", f"{total_output:,.0f}", help="Total tokens generated by AI assistant responses."
        )
    with col3:
        avg_tokens = df["total_tokens"].mean()
        st.metric(
            "Avg Tokens/Response",
            f"{avg_tokens:,.0f}",
            help="Average number of tokens (input + output) per AI response.",
        )
    with col4:
        # Calculate 24-hour activity
        # Get the timezone from the first timestamp
        tz = df["timestamp"].dt.tz if not df.empty else None
        last_24h = pd.Timestamp.now(tz=tz) - pd.Timedelta(hours=24)
        recent_count = len(df[df["timestamp"] > last_24h])
        st.metric("24h Activity", recent_count, help="Number of AI responses in the last 24 hours.")

    # Third row: cache metrics
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        cache_read = df["cache_read_input_tokens"].sum()
        st.metric(
            "Cache Read Tokens",
            f"{cache_read:,.0f}",
            help="Tokens read from cache. These cost only 10% of regular input tokens.",
        )
    with col2:
        cache_creation = df["cache_creation_input_tokens"].sum()
        st.metric(
            "Cache Creation Tokens",
            f"{cache_creation:,.0f}",
            help="Tokens stored in cache for future reuse. Charged at regular input rates.",
        )
    with col3:
        regular_input = df["input_tokens"].sum()
        st.metric("Regular Input Tokens", f"{regular_input:,.0f}", help="Standard input tokens charged at full price.")
    with col4:
        # Cache savings
        cache_savings = calculate_cache_savings(cache_read, regular_input, cache_creation)
        st.metric(
            "Cache Savings",
            f"{cache_savings:.1f}%",
            help="Percentage saved by using cached tokens (90% discount on cache reads).",
        )


def show_cost_calculation_details(df: pd.DataFrame) -> None:
    """Show cost calculation details in an expander.

    Args:
        df: Dataframe with token information
    """
    with st.expander("Cost Calculation Details"):
        st.caption("Cost formula per response:")
        st.code("""
Input cost = (input_tokens + cache_creation_tokens) * model_input_price / 1,000,000
Cache cost = cache_read_tokens * model_cache_price / 1,000,000  
Output cost = output_tokens * model_output_price / 1,000,000
Total cost = Input cost + Cache cost + Output cost
        """)

        # Show token totals
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Total Regular Input", f"{df['input_tokens'].sum():,.0f}")
            st.metric("Total Cache Creation", f"{df['cache_creation_input_tokens'].sum():,.0f}")
        with col2:
            st.metric("Total Cache Read", f"{df['cache_read_input_tokens'].sum():,.0f}")
            st.metric("Total Output", f"{df['output_tokens'].sum():,.0f}")
        with col3:
            st.metric("Total Responses", f"{len(df):,}")
            st.metric("Unique Models", df["model"].nunique())


def display_date_range(df: pd.DataFrame, total_days: Optional[int] = None) -> None:
    """Display the date range of the data.

    Args:
        df: Dataframe with timestamp column
        total_days: Optional pre-calculated total days
    """
    if df.empty or "timestamp" not in df.columns:
        return

    date_range = f"{df['timestamp'].min().strftime('%Y-%m-%d')} - {df['timestamp'].max().strftime('%Y-%m-%d')}"

    if total_days is None:
        total_days = (df["timestamp"].max() - df["timestamp"].min()).days + 1

    st.caption(f"Data Period: {date_range} ({total_days} days)")


def display_cost_metrics(
    total_cost: float, daily_avg_cost: float, cache_rate: float, avg_cost_per_response: float
) -> None:
    """Display cost-related metrics.

    Args:
        total_cost: Total cost in dollars
        daily_avg_cost: Daily average cost in dollars
        cache_rate: Cache hit rate percentage
        avg_cost_per_response: Average cost per response in dollars
    """
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric(
            "Total Cost", f"${total_cost:.2f}", help="Total cost calculated based on token usage and model pricing."
        )
    with col2:
        st.metric("Daily Avg Cost", f"${daily_avg_cost:.2f}", help="Average daily cost based on the data period.")
    with col3:
        st.metric(
            "Cache Hit Rate",
            f"{cache_rate:.1f}%",
            help="Percentage of input tokens served from cache (90% cheaper than regular input).",
        )
    with col4:
        st.metric("Avg Cost/Response", f"${avg_cost_per_response:.4f}", help="Average cost per AI response.")
